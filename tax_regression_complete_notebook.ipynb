{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e43015f1",
   "metadata": {},
   "source": [
    "# Tax Liability Prediction (Regression) â€” Complete Endâ€‘toâ€‘End Notebook ðŸ§¾ðŸ“ˆ\n",
    "\n",
    "This notebook is a **full regression ML project** built on the synthetic tax dataset.\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "Predict **`TaxLiability`** (continuous numeric target).\n",
    "\n",
    "## âœ… Includes\n",
    "- Data loading + sanity checks\n",
    "- **Advanced EDA (multiâ€‘level)**\n",
    "- Cleaning (handles NaN/inf safely)\n",
    "- Feature engineering\n",
    "- Preprocessing pipeline (numeric + categorical)\n",
    "- Train/Val/Test split\n",
    "- **6+ regression models**\n",
    "- Evaluation: **RMSE, MAE, RÂ², MAPE**\n",
    "- Crossâ€‘validation (compatible scoring)\n",
    "- Diagnostics: Pred vs Actual + residual plots\n",
    "- Permutation importance (**safe settings**, no length mismatch)\n",
    "- Save final deploymentâ€‘ready pipeline `.joblib`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 0) Setup\n",
    "# ============================\n",
    "DATA_PATH = \"tax_synthetic_ml_dataset.csv\"  # keep CSV in same folder as this notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb1c1e",
   "metadata": {},
   "source": [
    "## 1) Data Audit (Quality Checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing = missing[missing > 0]\n",
    "print(\"Columns with missing:\", len(missing))\n",
    "missing.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8955eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates\n",
    "print(\"Duplicate rows:\", int(df.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92017355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").T.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e58fc7",
   "metadata": {},
   "source": [
    "## 2) Define Target (Regression) + Safe Cleaning\n",
    "We predict **`TaxLiability`** and drop:\n",
    "- `AuditFlag` (classification label)\n",
    "- `EffectiveTaxRate` (derived from TaxLiability â†’ leakage)\n",
    "\n",
    "We also:\n",
    "- coerce target to numeric\n",
    "- replace inf with NaN\n",
    "- drop rows where **target is NaN** (prevents training error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"TaxLiability\"\n",
    "\n",
    "# Drop classification/leakage columns if present\n",
    "drop_cols = [\"AuditFlag\", \"EffectiveTaxRate\"]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "# Replace infinities in entire dataframe\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Force target numeric (bad strings -> NaN)\n",
    "df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
    "\n",
    "print(\"NaNs in target before:\", int(df[TARGET].isna().sum()))\n",
    "\n",
    "# Drop rows with NaN target (recommended)\n",
    "df = df.dropna(subset=[TARGET]).reset_index(drop=True)\n",
    "\n",
    "print(\"Shape after target cleanup:\", df.shape)\n",
    "print(\"NaNs in target after:\", int(df[TARGET].isna().sum()))\n",
    "\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "# Final safety: remove non-finite target rows (should be none after dropna)\n",
    "mask = np.isfinite(y.to_numpy())\n",
    "X = X.loc[mask].reset_index(drop=True)\n",
    "y = y.loc[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Final X,y:\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfa93b",
   "metadata": {},
   "source": [
    "## 3) Advanced EDA (Level 1): Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "y.hist(bins=60)\n",
    "plt.title(\"Target Distribution: TaxLiability\")\n",
    "plt.xlabel(\"TaxLiability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness:\", float(y.skew()))\n",
    "print(\"Kurtosis:\", float(y.kurtosis()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd26e9",
   "metadata": {},
   "source": [
    "## 4) Advanced EDA (Level 2): Numeric Distributions & Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_all = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols_all = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "major_num = [\"Age\",\"AnnualIncome\",\"BusinessIncome\",\"CapitalGains\",\"DeductionsTotal\",\"TaxableIncome\",\"StandardDeduction\",\"HealthInsurancePremium\"]\n",
    "major_num = [c for c in major_num if c in X.columns]\n",
    "\n",
    "for col in major_num:\n",
    "    plt.figure()\n",
    "    X[col].hist(bins=50)\n",
    "    plt.title(f\"Distribution: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "def iqr_outlier_count(s):\n",
    "    s = s.dropna()\n",
    "    if len(s) == 0:\n",
    "        return 0\n",
    "    q1, q3 = np.percentile(s, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    return int(((s < lo) | (s > hi)).sum())\n",
    "\n",
    "outlier_counts = {c: iqr_outlier_count(X[c]) for c in major_num}\n",
    "pd.Series(outlier_counts).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8bf2f4",
   "metadata": {},
   "source": [
    "## 5) Advanced EDA (Level 3): Relationships with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c49824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots (sample for speed)\n",
    "sample_idx = X.sample(n=min(6000, len(X)), random_state=42).index\n",
    "\n",
    "for col in [\"TaxableIncome\",\"AnnualIncome\",\"BusinessIncome\",\"CapitalGains\",\"DeductionsTotal\"]:\n",
    "    if col not in X.columns:\n",
    "        continue\n",
    "    plt.figure()\n",
    "    plt.scatter(X.loc[sample_idx, col], y.loc[sample_idx], alpha=0.25)\n",
    "    plt.title(f\"{col} vs TaxLiability\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"TaxLiability\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical: target mean by category\n",
    "for col in cat_cols_all:\n",
    "    stats = df.groupby(col)[TARGET].agg([\"mean\",\"median\",\"count\"]).sort_values(\"mean\", ascending=False)\n",
    "    display(stats.head(10))\n",
    "    plt.figure()\n",
    "    stats[\"mean\"].head(12).plot(kind=\"bar\")\n",
    "    plt.title(f\"Mean TaxLiability by {col} (Top 12)\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Mean TaxLiability\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1010d",
   "metadata": {},
   "source": [
    "## 6) Advanced EDA (Level 4): Correlation Heatmap (Numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f124631",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[num_cols_all + [TARGET]].corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr.values, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.title(\"Correlation Heatmap (Numeric)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee55f60",
   "metadata": {},
   "source": [
    "## 7) Feature Engineering\n",
    "Adds:\n",
    "- TotalIncome\n",
    "- BusinessIncomeRatio\n",
    "- DeductionsRatio\n",
    "- IncomePerDependent\n",
    "- LogTotalIncome\n",
    "All ratios use +1 to avoid divide-by-zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df.copy()\n",
    "\n",
    "df_fe[\"TotalIncome\"] = df_fe[\"AnnualIncome\"] + df_fe[\"BusinessIncome\"] + df_fe[\"CapitalGains\"]\n",
    "df_fe[\"BusinessIncomeRatio\"] = df_fe[\"BusinessIncome\"] / (df_fe[\"AnnualIncome\"] + 1.0)\n",
    "df_fe[\"DeductionsRatio\"] = df_fe[\"DeductionsTotal\"] / (df_fe[\"TotalIncome\"] + 1.0)\n",
    "df_fe[\"IncomePerDependent\"] = df_fe[\"TotalIncome\"] / (df_fe[\"Dependents\"] + 1.0)\n",
    "df_fe[\"LogTotalIncome\"] = np.log1p(df_fe[\"TotalIncome\"])\n",
    "\n",
    "# Replace any inf that might appear (shouldn't)\n",
    "df_fe = df_fe.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Drop rows where engineered columns became NaN (rare)\n",
    "engineered_cols = [\"TotalIncome\",\"BusinessIncomeRatio\",\"DeductionsRatio\",\"IncomePerDependent\",\"LogTotalIncome\"]\n",
    "df_fe = df_fe.dropna(subset=engineered_cols + [TARGET]).reset_index(drop=True)\n",
    "\n",
    "X = df_fe.drop(columns=[TARGET])\n",
    "y = df_fe[TARGET].astype(float)\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"After FE X,y:\", X.shape, y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f525bbb",
   "metadata": {},
   "source": [
    "## 8) Train / Validation / Test Split (70/15/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2b0fc",
   "metadata": {},
   "source": [
    "## 9) Preprocessing Pipeline (Numeric + Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f727eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59f473",
   "metadata": {},
   "source": [
    "## 10) Metrics (Compatible with Older/Newer scikit-learn)\n",
    "We compute RMSE manually (avoids `squared=False` incompatibility).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)  # no squared=...\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    mae = float(mean_absolute_error(y_true, y_pred))\n",
    "    r2 = float(r2_score(y_true, y_pred))\n",
    "    denom = np.clip(np.abs(np.asarray(y_true)), 1.0, None)\n",
    "    mape = float(np.mean(np.abs((np.asarray(y_true) - np.asarray(y_pred)) / denom)) * 100)\n",
    "    return {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"MAPE_%\": mape}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f114def",
   "metadata": {},
   "source": [
    "## 11) Train 6+ Regression Models + Validation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"Lasso\": Lasso(alpha=0.0008, random_state=42, max_iter=20000),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.001, l1_ratio=0.35, random_state=42, max_iter=20000),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=350, random_state=42, n_jobs=-1),\n",
    "    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=500, random_state=42, n_jobs=-1),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "val_results = []\n",
    "trained = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred_val = pipe.predict(X_val)\n",
    "    m = regression_metrics(y_val, pred_val)\n",
    "    m[\"Model\"] = name\n",
    "    val_results.append(m)\n",
    "    trained[name] = pipe\n",
    "    print(name, m)\n",
    "\n",
    "val_df = pd.DataFrame(val_results).set_index(\"Model\").sort_values([\"RMSE\",\"MAE\"])\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffc512",
   "metadata": {},
   "source": [
    "## 12) Cross-Validation (CV) for Top Models (Compatible scoring)\n",
    "We use `neg_mean_squared_error` then take sqrt to get RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "top_models = val_df.head(4).index.tolist()\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_rows = []\n",
    "for name in top_models:\n",
    "    pipe = trained[name]\n",
    "    scores = cross_val_score(pipe, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "    cv_rmse = np.sqrt(-scores)\n",
    "    cv_rows.append({\n",
    "        \"Model\": name,\n",
    "        \"CV_RMSE_mean\": float(cv_rmse.mean()),\n",
    "        \"CV_RMSE_std\": float(cv_rmse.std()),\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_rows).set_index(\"Model\").sort_values(\"CV_RMSE_mean\")\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e5b12",
   "metadata": {},
   "source": [
    "## 13) Final Model: Refit on Train+Val and Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034fd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = val_df.index[0]\n",
    "print(\"Best model by validation RMSE:\", best_name)\n",
    "\n",
    "best_pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", models[best_name])])\n",
    "\n",
    "X_trval = pd.concat([X_train, X_val], axis=0)\n",
    "y_trval = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "best_pipe.fit(X_trval, y_trval)\n",
    "\n",
    "pred_test = best_pipe.predict(X_test)\n",
    "test_metrics = regression_metrics(y_test, pred_test)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f18b0",
   "metadata": {},
   "source": [
    "## 14) Diagnostics: Pred vs Actual + Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_test, pred_test, alpha=0.3)\n",
    "plt.title(f\"Predicted vs Actual (Test) â€” {best_name}\")\n",
    "plt.xlabel(\"Actual TaxLiability\")\n",
    "plt.ylabel(\"Predicted TaxLiability\")\n",
    "plt.show()\n",
    "\n",
    "resid = y_test - pred_test\n",
    "\n",
    "plt.figure()\n",
    "pd.Series(resid).hist(bins=60)\n",
    "plt.title(\"Residual Distribution (Test)\")\n",
    "plt.xlabel(\"Residual (Actual - Pred)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(pred_test, resid, alpha=0.3)\n",
    "plt.axhline(0, color=\"red\")\n",
    "plt.title(\"Residuals vs Predicted (Test)\")\n",
    "plt.xlabel(\"Predicted TaxLiability\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e3483",
   "metadata": {},
   "source": [
    "## 15) Permutation Importance (Safe + Correct Feature Names)\n",
    "- Uses **original input columns** (no oneâ€‘hot length mismatch)\n",
    "- Uses **n_jobs=1** to avoid joblib disk/pickling issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "X_imp = X_test.sample(n=min(1500, len(X_test)), random_state=42)\n",
    "y_imp = y_test.loc[X_imp.index]\n",
    "\n",
    "r = permutation_importance(\n",
    "    best_pipe,\n",
    "    X_imp,\n",
    "    y_imp,\n",
    "    n_repeats=3,\n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "feature_names = X_imp.columns.tolist()\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance_mean\": r.importances_mean,\n",
    "    \"importance_std\": r.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "display(imp_df.head(20))\n",
    "\n",
    "topk = imp_df.head(15).iloc[::-1]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(topk[\"feature\"], topk[\"importance_mean\"])\n",
    "plt.title(\"Permutation Importance (Original Features)\")\n",
    "plt.xlabel(\"Importance (MSE impact)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce109f04",
   "metadata": {},
   "source": [
    "## 16) Save Final Pipeline (Deploymentâ€‘Ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "ARTIFACT_PATH = \"tax_liability_regression_pipeline.joblib\"\n",
    "joblib.dump(best_pipe, ARTIFACT_PATH)\n",
    "print(\"Saved:\", ARTIFACT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a531f2",
   "metadata": {},
   "source": [
    "## 17) Quick Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = X_test.iloc[[0]].copy()\n",
    "pred_example = float(best_pipe.predict(example_row)[0])\n",
    "print(\"Example prediction TaxLiability:\", pred_example)\n",
    "example_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60c486",
   "metadata": {},
   "source": [
    "## âœ… Conclusion (Vivaâ€‘Ready)\n",
    "- We framed the task as **regression** to predict **TaxLiability**\n",
    "- Performed EDA, feature engineering, and trained multiple models\n",
    "- Selected best model using validation RMSE + confirmed with CV\n",
    "- Ran diagnostics + feature importance\n",
    "- Saved a single pipeline artifact for Streamlit/FastAPI deployment\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
